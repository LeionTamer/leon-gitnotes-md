# Adelaide DDD Conference

## Keynote

The keynote was delivered by Geoffrey Huntley

Blogs can be found in [https://ghuntley.com/](https://ghuntley.com/) with references to the following blogs
 - oh-fuck
 - agent
 - mirrors

We should build more agents to understand how agents work

There are different guidelines / tuning-guides for each model. An example would be yelling (all-upper case). Anthropic recommends it, OpenAI does not.

We should use one context window per task, ie. create a new window for each new chat. 

Lesser context is better.

Take note that your system prompt and the other prompts such as steering guides will take up space on your context window.

MCP uses a lot of tokens.

You must understand how agents work, understand what is an agentic loop.

The Overton window is the range of policies and ideas that the public will accept at a given time. It is a dynamic concept that shifts, expands, or shrinks over time, and can be influenced by events, political movements, and public opinion. The window can be used to describe what is considered politically acceptable versus what is too radical or unthinkable for the mainstream to consider. 

Creating a new programming could cost 5k for a new language.
See [cursed-lang](https://cursed-lang.org/)

LLM Outcomes is a reflection of people skills

Different models for different applications. An example would be to use Grok for security research. Anthropic is not good for summarisation. OpenAI is good as an oracle.

Take-away is to be a product engineer with the use of agents

## Notes to self

- What is Kimi K2?
- Explore [agents.md](https://agents.md/)
- Explore tuning guides for OpenAI and Google Gemini
- Make tuning agents for current work/project
- Something to try is to create  a headless reverse-engineering agent


